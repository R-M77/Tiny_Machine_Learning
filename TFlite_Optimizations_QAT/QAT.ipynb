{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import InputLayer, Reshape, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is done so to show effects of Quantization Aware training\"\"\"\n",
    "\"\"\"Start of non-QAT\"\"\"\n",
    "# Load mnist dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_img, train_label),(test_img, test_label) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data/img\n",
    "train_img = train_img/255.0\n",
    "test_img = test_img/255.0\n",
    "\n",
    "# Setup model architecture\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(28,28)),\n",
    "    Reshape(target_shape=(28,28,1)),\n",
    "    Conv2D(filters=12, kernel_size=(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 6s 2ms/step - loss: 0.3062 - accuracy: 0.9128 - val_loss: 0.1200 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'End of non-QAT'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "OPT = 'adam'\n",
    "LOSS = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "METRICS = ['accuracy']\n",
    "model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "model.fit(train_img, train_label, epochs=1, validation_split=0.1)\n",
    "\n",
    "\"\"\"End of non-QAT\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer (QuantizeLaye (None, 28, 28)            3         \n",
      "_________________________________________________________________\n",
      "quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "quant_flatten (QuantizeWrapp (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 10)                20295     \n",
      "=================================================================\n",
      "Total params: 20,448\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"QAT optimization\"\"\"\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "qat_model = quantize_model(model)\n",
    "\n",
    "# recompile qat model\n",
    "qat_model.compile(optimizer=OPT,loss=LOSS,metrics=METRICS)\n",
    "\n",
    "qat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 195ms/step - loss: 0.1564 - accuracy: 0.9578 - val_loss: 0.1784 - val_accuracy: 0.9500\n",
      "baseline accuracy is: 0.9621999859809875\n",
      "QAT model accuracy is: 0.9616000056266785\n"
     ]
    }
   ],
   "source": [
    "# train and fit against baseline\n",
    "train_img_subset = train_img[0:1000]\n",
    "train_label_subset = train_label[0:1000]\n",
    "\n",
    "qat_model.fit(train_img_subset, train_label_subset, batch_size=500, epochs=1, validation_split=0.1)\n",
    "\n",
    "_,baseline_model_acc = model.evaluate(test_img, test_label, verbose=0)\n",
    "_,qat_model_acc = qat_model.evaluate(test_img, test_label, verbose=0)\n",
    "\n",
    "print('baseline accuracy is: {}'.format(baseline_model_acc))\n",
    "print('QAT model accuracy is: {}'.format(qat_model_acc))\n",
    "\n",
    "# Note: qat_model is not yet quantized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as reshape_layer_call_and_return_conditional_losses, reshape_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, flatten_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmppb0ujr3k\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmppb0ujr3k\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24592"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantize and convert to TFLite\n",
    "tfl_converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
    "tfl_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_quantized_model = tfl_converter.convert()\n",
    "tflite_q_model = pathlib.Path('tflite_quant_model.tflite')\n",
    "tflite_q_model.write_bytes(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TFLite accuracy | Evaluate and compare\n",
    "# Define fn to evaluate models\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    # predict every img in the test dataset\n",
    "    prediction = []\n",
    "    for i, test_im in enumerate(test_img):\n",
    "        if i %1000 == 0:\n",
    "            print('evaluated on {} reslts so far'.format(i))\n",
    "        \n",
    "        # convert to float32 to match model's input data format\n",
    "        test_im = np.expand_dims(test_im, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_im)\n",
    "\n",
    "        # Inference\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # fin digit with max probability\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    # compare results with actual labels and compute acc\n",
    "    prediction = np.array(prediction)\n",
    "    accuracy = (prediction == test_label).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated on 0 reslts so far\n",
      "evaluated on 1000 reslts so far\n",
      "evaluated on 2000 reslts so far\n",
      "evaluated on 3000 reslts so far\n",
      "evaluated on 4000 reslts so far\n",
      "evaluated on 5000 reslts so far\n",
      "evaluated on 6000 reslts so far\n",
      "evaluated on 7000 reslts so far\n",
      "evaluated on 8000 reslts so far\n",
      "evaluated on 9000 reslts so far\n",
      "\n",
      "\n",
      "QAT TFLite acc: 0.9617\n",
      "QAT TF acc: 0.9616000056266785\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_quantized_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_acc = evaluate_model(interpreter)\n",
    "\n",
    "print('QAT TFLite acc: {}'.format(test_acc))\n",
    "print('QAT TF acc: {}'.format(qat_model_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpwgq5mntc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpwgq5mntc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float_model size: 0.08058547973632812 MB\n",
      "quantized_model size: 0.0234527587890625 MB\n"
     ]
    }
   ],
   "source": [
    "# Compress model by 4x\n",
    "float_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_float_model = float_converter.convert()\n",
    "\n",
    "# find model size\n",
    "_,float_file = tempfile.mkstemp('.tflite')\n",
    "_,quant_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quant_file, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n",
    "with open(float_file, 'wb') as f:\n",
    "    f.write(tflite_float_model)\n",
    "\n",
    "print(\"float_model size: {} MB\".format(os.path.getsize(float_file)/float(2**20)))\n",
    "print(\"quantized_model size: {} MB\".format(os.path.getsize(quant_file)/float(2**20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/baseline_q_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/baseline_q_model\\assets\n",
      "WARNING:absl:Found untraced functions such as reshape_layer_call_and_return_conditional_losses, reshape_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, flatten_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tf_qat_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tf_qat_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model(s)\n",
    "# using savedModel\n",
    "model.save('saved_model/baseline_q_model')\n",
    "qat_model.save('saved_model/tf_qat_model')\n",
    "# using hdf5\n",
    "model.save('baseline_model.h5')\n",
    "qat_model.save('tf_q_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save tflite model(s)\n",
    "tflite_model_file = pathlib.Path('tflite_float_model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_float_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
