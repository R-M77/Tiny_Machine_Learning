{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import InputLayer, Reshape, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is done so to show effects of Quantization Aware training\"\"\"\n",
    "\"\"\"Start of non-QAT\"\"\"\n",
    "# Load mnist dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_img, train_label),(test_img, test_label) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data/img\n",
    "train_img = train_img/255.0\n",
    "test_img = test_img/255.0\n",
    "\n",
    "# Setup model architecture\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(28,28)),\n",
    "    Reshape(target_shape=(28,28,1)),\n",
    "    Conv2D(filters=12, kernel_size=(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2994 - accuracy: 0.9151 - val_loss: 0.1140 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'End of non-QAT'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "OPT = 'adam'\n",
    "LOSS = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "METRICS = ['accuracy']\n",
    "model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "model.fit(train_img, train_label, epochs=1, validation_split=0.1)\n",
    "\n",
    "\"\"\"End of non-QAT\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer_1 (QuantizeLa (None, 28, 28)            3         \n",
      "_________________________________________________________________\n",
      "quant_reshape_2 (QuantizeWra (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_2 (QuantizeWrap (None, 26, 26, 12)        147       \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d_2 (Quant (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "quant_flatten_2 (QuantizeWra (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense_2 (QuantizeWrapp (None, 10)                20295     \n",
      "=================================================================\n",
      "Total params: 20,448\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"QAT optimization\"\"\"\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "qat_model = quantize_model(model)\n",
    "\n",
    "# recompile qat model\n",
    "qat_model.compile(optimizer=OPT,loss=LOSS,metrics=METRICS)\n",
    "\n",
    "qat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1287 - accuracy: 0.9656 - val_loss: 0.1584 - val_accuracy: 0.9700\n",
      "baseline accuracy is: 0.9617999792098999\n",
      "QAT model accuracy is: 0.9611999988555908\n"
     ]
    }
   ],
   "source": [
    "# train and fit against baseline\n",
    "train_img_subset = train_img[0:1000]\n",
    "train_label_subset = train_label[0:1000]\n",
    "\n",
    "qat_model.fit(train_img_subset, train_label_subset, batch_size=500, epochs=1, validation_split=0.1)\n",
    "\n",
    "_,baseline_model_acc = model.evaluate(test_img, test_label, verbose=0)\n",
    "_,qat_model_acc = qat_model.evaluate(test_img, test_label, verbose=0)\n",
    "\n",
    "print('baseline accuracy is: {}'.format(baseline_model_acc))\n",
    "print('QAT model accuracy is: {}'.format(qat_model_acc))\n",
    "\n",
    "# Note: qat_model is not yet quantized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as reshape_2_layer_call_fn, reshape_2_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses, flatten_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmp7f_bgbj2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmp7f_bgbj2\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24688"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantize and convert to TFLite\n",
    "tfl_converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
    "tfl_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_quantized_model = tfl_converter.convert()\n",
    "tflite_q_model = pathlib.Path('tflite_quant_model.tflite')\n",
    "tflite_q_model.write_bytes(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TFLite accuracy | Evaluate and compare\n",
    "# Define fn to evaluate models\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    # predict every img in the test dataset\n",
    "    prediction = []\n",
    "    for i, test_im in enumerate(test_img):\n",
    "        if i %1000 == 0:\n",
    "            print('evaluated on {} reslts so far'.format(i))\n",
    "        \n",
    "        # convert to float32 to match model's input data format\n",
    "        test_im = np.expand_dims(test_im, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_im)\n",
    "\n",
    "        # Inference\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # fin digit with max probability\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    # compare results with actual labels and compute acc\n",
    "    prediction = np.array(prediction)\n",
    "    accuracy = (prediction == test_label).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated on 0 reslts so far\n",
      "evaluated on 1000 reslts so far\n",
      "evaluated on 2000 reslts so far\n",
      "evaluated on 3000 reslts so far\n",
      "evaluated on 4000 reslts so far\n",
      "evaluated on 5000 reslts so far\n",
      "evaluated on 6000 reslts so far\n",
      "evaluated on 7000 reslts so far\n",
      "evaluated on 8000 reslts so far\n",
      "evaluated on 9000 reslts so far\n",
      "\n",
      "\n",
      "QAT TFLite acc: 0.9612\n",
      "QAT TF acc: 0.9611999988555908\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_quantized_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_acc = evaluate_model(interpreter)\n",
    "\n",
    "print('QAT TFLite acc: {}'.format(test_acc))\n",
    "print('QAT TF acc: {}'.format(qat_model_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpl5yqqoon\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpl5yqqoon\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float_model size: 0.080657958984375 MB\n",
      "quantized_model size: 0.0235443115234375 MB\n"
     ]
    }
   ],
   "source": [
    "# Compress model by 4x\n",
    "float_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_float_model = float_converter.convert()\n",
    "\n",
    "# find model size\n",
    "_,float_file = tempfile.mkstemp('.tflite')\n",
    "_,quant_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quant_file, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n",
    "with open(float_file, 'wb') as f:\n",
    "    f.write(tflite_float_model)\n",
    "\n",
    "print(\"float_model size: {} MB\".format(os.path.getsize(float_file)/float(2**20)))\n",
    "print(\"quantized_model size: {} MB\".format(os.path.getsize(quant_file)/float(2**20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/baseline_q_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/baseline_q_model\\assets\n",
      "WARNING:absl:Found untraced functions such as reshape_2_layer_call_fn, reshape_2_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses, flatten_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tf_qat_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tf_qat_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model(s)\n",
    "# using savedModel\n",
    "model.save('saved_model/baseline_q_model')\n",
    "qat_model.save('saved_model/tf_qat_model')\n",
    "# using hdf5\n",
    "model.save('baseline_model.h5')\n",
    "qat_model.save('tf_q_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "memoryview: a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_69192/2891304087.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtflite_q_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tflite_quant_model.tflite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtflite_q_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_quantized_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\pathlib.py\u001b[0m in \u001b[0;36mwrite_bytes\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \"\"\"\n\u001b[0;32m   1273\u001b[0m         \u001b[1;31m# type-check for the buffer interface before truncating the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[0mview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: memoryview: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# Save tflite model(s)\n",
    "tflite_model_file = pathlib.Path('tflite_float_model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_float_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
